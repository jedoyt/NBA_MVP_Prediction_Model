{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA MVP Prediction Model\n",
    "Creating a Machine Learning Model that predicts the possible candidates for MVP on a given (and preferably current) NBA Season.\n",
    "\n",
    "Before running the `datasetFactory.py`, it's best to read and test the codes on this notebook. This environment is a great tool for familiarizing with the codes behind all of these steps.\n",
    "\n",
    "This notebook contains these 4 major parts:\n",
    "\n",
    "1. Webscraping for Data\n",
    "\n",
    "    Methods from `nbaPlayers_StatsScraper.py` module:\n",
    "    - `scrapeNBAStats(year)`\n",
    "    - `scrapeMVPs()`\n",
    "    \n",
    "\n",
    "2. Preparation of Datasets\n",
    "\n",
    "    Running `datasetFactory.py` with the folowing outputs\n",
    "    - `training_data.csv`\n",
    "\n",
    "\n",
    "3. Building the Machine Learning Model\n",
    "\n",
    "    Main Steps:\n",
    "    \n",
    "    a. PREPARE data - creating DataFrames and data cleansing\n",
    "    \n",
    "    b. DEFINE model - choose model and instantiate\n",
    "    \n",
    "    c. FIT model - train the model\n",
    "    \n",
    "    d. PREDICT\n",
    "    \n",
    "    e. EVALUATE - using mean absolute error\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Webscraping for Data\n",
    "## `nbaPlayers_StatsScraper.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: `scrapeNBAStats(year)`\n",
    "Web Scraping Source: e.g. for year 2019 -- https://www.basketball-reference.com/leagues/NBA_2019_per_game.html\n",
    "\n",
    "**OUTPUT**: `nbaPlayers_statsPerGame_YYYY.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeNBAStats(year=datetime.now().year):\n",
    "    '''\n",
    "    Scrapes for per game statistics of all NBA Players on a given season\n",
    "    \n",
    "    scrapeNBAStats(year=datetime.now().year)\n",
    "    year: int object; defaults to current year\n",
    "    \n",
    "    OUTPUT: 'nbaPlayers_statsPerGame_yyyy.csv'\n",
    "    'yyyy' is the year of the season\n",
    "    '''\n",
    "    # URL to be requested\n",
    "    url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\".format(year)\n",
    "    \n",
    "    # Create requests object: res\n",
    "    print(\"Now requesting...\", url)\n",
    "    res = requests.get(url)\n",
    "    print(res.raise_for_status)\n",
    "\n",
    "    # Create BeautifulSoup Object: `soup`\n",
    "    soup = BeautifulSoup(res.text, features='lxml')\n",
    "    print(\"Created BeautifulSoup object: soup\")\n",
    "    \n",
    "    # Parse the column headers and store them in a list\n",
    "    headers = soup.thead.getText().split('\\n')[3:-2] # Slicers are intended to exclude unnecessary headers\n",
    "    \n",
    "    # Parse the rows(player stats) and store them in a list\n",
    "    rows = soup.findAll('tr')[1:]\n",
    "    \n",
    "    # Create the rows for each player and their stats as a list of list\n",
    "    player_stats = []\n",
    "    for i in range(0,len(rows)):\n",
    "        try:\n",
    "            row = [td.getText() for td in rows[i]][1:] # Parses the texts within the tags and excludes the values\n",
    "                                                    # under 'Rk' column since it was also excluded in our headers\n",
    "            player_stats.append(row)\n",
    "        except AttributeError: # For every 20 iteration of this loop, it encounters this error\n",
    "                                # and needs to pass over it and continue on the next iteration\n",
    "            pass\n",
    "\n",
    "    print(\"Scraping and Parsing Complete!\")         \n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    stats = pd.DataFrame(player_stats, columns=headers)\n",
    "    \n",
    "    season_prefix = str(year-1)\n",
    "    season_suffix = str(year)[2:]\n",
    "    \n",
    "    season = \"{}-{}\".format(season_prefix,season_suffix)\n",
    "    \n",
    "    stats['Season'] = season\n",
    "    \n",
    "    # Create a csv file from this DataFrame\n",
    "    filename = 'nbaPlayers_statsPerGame_{}.csv'.format(year)\n",
    "    stats.to_csv(filename,header=True, index=False)\n",
    "    print(\"Generated csv file last {}: {}\".format(datetime.now(),filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run\n",
    "scrapeNBAStats(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check csv files by viewing them using pandas DataFrames\n",
    "season_df = pd.read_csv('nbaPlayers_statsPerGame_2019.csv')\n",
    "\n",
    "season_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 2: `scrapeMVPs()`\n",
    "Scrapes for NBA MVPs from to 2000 to 2018\n",
    "    \n",
    "**OUTPUT:** `nbaMVPs.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeMVPs():\n",
    "    '''\n",
    "    Scrapes for NBA MVPs from to 2000 to 2018\n",
    "    OUTPUT: 'nbaMVPs.csv'\n",
    "    '''\n",
    "    # URL to be requested\n",
    "    url = \"https://www.basketball-reference.com/awards/mvp.html\"\n",
    "\n",
    "    # Create requests object: res\n",
    "    print(\"Now requesting...\", url)\n",
    "    res = requests.get(url)\n",
    "    print(res.raise_for_status)\n",
    "\n",
    "    # Create BeautifulSoup Object: `soup`\n",
    "    soup = BeautifulSoup(res.text, features='lxml')\n",
    "    print(\"Created BeautifulSoup object: soup\")\n",
    "    \n",
    "    # Parse the table\n",
    "    html_table = soup.findAll('tr')[1:] # Sliced first header\n",
    "\n",
    "    # Parse the column headers and store them in a list\n",
    "    headers = [col_head.getText() for col_head in html_table][0].split('\\n')[1:4] # Slicers are intended to exclude unnecessary headers\n",
    "\n",
    "    # Parse the rows and store them in a list\n",
    "    raw_rows = [col_head.getText() for col_head in html_table][1:21]\n",
    "    players = []\n",
    "    for row in raw_rows:\n",
    "        season = row[:7]\n",
    "        league = row[7:10]\n",
    "        player = row[10:].split('(V)')[0]\n",
    "        players.append([season,league,player])\n",
    "    \n",
    "    print(\"Scraping and Parsing Complete!\")         \n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    mvp = pd.DataFrame(players, columns=headers)\n",
    "\n",
    "    # Create a csv file from this DataFrame\n",
    "    filename = 'nbaMVPs.csv'\n",
    "    mvp.to_csv(filename,header=True, index=False)\n",
    "    print(\"Generated csv file last {}: {}\".format(datetime.now(),filename))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run:\n",
    "scrapeMVPs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check csv files by viewing them using pandas DataFrames\n",
    "mvp_df = pd.read_csv('nbaMVPs.csv')\n",
    "\n",
    "mvp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparation of Datasets\n",
    "\n",
    "## `datasetFactory.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to import these two modules for this notebook.\n",
    "#from nbaPlayers_StatsScraper import scrapeNBAStats\n",
    "#from nbaPlayers_StatsScraper import scrapeMVPs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Build a training dataset consisting of complete stats from year 2000 to 2018\n",
    "\n",
    "##### UNCOMMENT TO GENERATE CSVs OF NBA STATS #####\n",
    "years = [i for i in range(2000,2019)]\n",
    "\n",
    "for i in years:\n",
    "    scrapeNBAStats(i)\n",
    "##### UNCOMMENT BLOCK ENDS HERE ###################\n",
    "\n",
    "# Create an initial DataFrame for the year 2000\n",
    "training_df = pd.read_csv('nbaPlayers_statsPerGame_2000.csv')\n",
    "\n",
    "# Then create a for loop to concatenate the stats from 2001 to 2018\n",
    "# to the DataFrame, \"training_df\"\n",
    "years = [year for year in range(2001,2019)]\n",
    "\n",
    "for season in years:\n",
    "    filename = 'nbaPlayers_statsPerGame_{}.csv'.format(season)\n",
    "    df = pd.read_csv(filename)\n",
    "    training_df = pd.concat([training_df,df])\n",
    "\n",
    "# This shall be the training data.\n",
    "# Generate a csv file out of this compilation of stats.\n",
    "training_df.to_csv('training_data.csv', header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check csv files by viewing them using pandas DataFrames\n",
    "train_df = pd.read_csv('training_data.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building the Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn modules\n",
    "\n",
    "# PREPARE\n",
    "\n",
    "# DEFINE\n",
    "\n",
    "# FIT\n",
    "\n",
    "# PREDICT\n",
    "\n",
    "# EVALUATE\n",
    "\n",
    "# FINAL PREDICTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
