{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA_MVP_Prediction_Model\n",
    "\n",
    "### Requirements/Dependencies:\n",
    "1. Have Anaconda installed in your system: https://www.anaconda.com/distribution/\n",
    "   - I recommend using Spyder(included in Anaconda Distribution) for the running the python scripts.\n",
    "   - You can run Spyder through Anaconda Navigator or through terminal by typing 'Spyder' then press Enter.\n",
    "2. Make sure the following modules/packages are available:\n",
    "   - numpy, pandas, requests, BeautifulSoup4, datetime, sklearn (All of these are built-in packages in Anaconda)\n",
    "\n",
    "### Quick Steps:\n",
    "1. Create the following folders for storage of generated csv files:\n",
    "   - `per_game_stats`\n",
    "   - `totals_stats`\n",
    "2. Run first the `datasetFactory.py` to generate the csv files\n",
    "3. Then run `randForest.py` to run predictions\n",
    "Note: Recommended IDE is Spyder(from Anaconda Distribution) due to many built in libraries that may not be available when running just IDLE the comes with the typical Python installer.\n",
    "\n",
    "The objective of the predictive model is to return a number of players from the current season that have the highest potential to be the next MVP using statistics from years 1957 to 2019 as the training dataset.\n",
    "\n",
    "This repository initially contains the following files\n",
    "1. `NBA MVP Prediction Model - Notes.ipynb` --> This notebook is where I plan everything from pseudo code to final code before I paste them to the respective python files: `datasetFactory.py`, `nbaPlayers_StatsScraper.py`,`randForest.py`\n",
    "\n",
    "2. `nbaPlayers_StatsScraper.py` --> A module containing two methods for webscraping data https://www.basketball-reference.com/\n",
    "3. `datasetFactory.py` --> Running this generates csv files of webscraped data from https://www.basketball-reference.com/\n",
    "4. `randForest.py` --> Contains the Machine Learning Model. Now currently using Random Forest Regression. But I might consider another model that is more applicable.\n",
    "\n",
    "The notebook, `NBA MVP Prediction Model - Notes.ipynb`, elaborates these 4 major steps:\n",
    "\n",
    "## 1. Webscraping for Data\n",
    "\n",
    "Methods from `nbaPlayers_StatsScraper.py` module:\n",
    "\n",
    "`scrapeNBAStats(year,type)`\n",
    "`scrapeMVPs()`\n",
    "\n",
    "## 2. Preparation of Dataset/s\n",
    "\n",
    "Running `datasetFactory.py` delivers these outputs:\n",
    "1. csv files of NBA Players Statistics Per Game for every season (1956-57 to 2018-19)\n",
    "2. `training_data.csv`\n",
    "3. `nbaMVPs.csv`\n",
    "\n",
    "## 3. Building the Machine Learning Model\n",
    "Running `randForest.py` delivers these csv outputs:\n",
    "1. `mvpTop10candidates.csv`\n",
    "2. `CompletePredictions.csv`\n",
    "\n",
    "The script shall perform these main steps:\n",
    "\n",
    "a. PREPARE data - creating DataFrames and pre-processing\n",
    "\n",
    "b. DEFINE model - choose model and instantiate\n",
    "\n",
    "c. FIT model - train the model\n",
    "\n",
    "d. PREDICT - Create a dataframe for the stats of current season.\n",
    "   \n",
    "   As of this time, the current season is 2019-20.\n",
    "\n",
    "e. EVALUATE - using mean absolute error (only shown in the .ipynb file)\n",
    "\n",
    "f. RESULTS - display top 10 potential MVPs and the complete predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Webscraping for Data\n",
    "## `nbaPlayers_StatsScraper.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 1: `scrapeNBAStats(year,type='per_game')`\n",
    "Web Scraping Source: e.g. for year 2019 -- https://www.basketball-reference.com/leagues/NBA_2019_per_game.html\n",
    "\n",
    "**OUTPUT**: `nbaPlayers_stats_{type}_{year}.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeNBAStats(year=datetime.now().year, type='per_game'):\n",
    "    '''\n",
    "    Scrapes for per game statistics of all NBA Players on a given season\n",
    "    \n",
    "    scrapeNBAStats(year=datetime.now().year, type='per_game')\n",
    "    year: int object; defaults to current year.\n",
    "          Pertains to the season--e.g. For season 2003-04, year to input is 2004\n",
    "    type: str object; Only two choices-- 'per-game' or 'totals'. Defaults to 'per_game'\n",
    "    \n",
    "    OUTPUT: 'nbaPlayers_statsPerGame_yyyy.csv'\n",
    "    'yyyy' is the year of the season\n",
    "    '''\n",
    "\n",
    "    # URL to be requested\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_{type}.html\"\n",
    "    \n",
    "    # Create requests object: res\n",
    "    print(\"\\nNow requesting...\", url)\n",
    "    res = requests.get(url)\n",
    "    print(res.raise_for_status)\n",
    "\n",
    "    # Create BeautifulSoup Object: `soup`\n",
    "    soup = BeautifulSoup(res.text, features='lxml')\n",
    "    print(\"Created BeautifulSoup object: soup\")\n",
    "    \n",
    "    # Parse the column headers and store them in a list\n",
    "    headers = soup.thead.getText().split('\\n')[3:-2] # Slicers are intended to exclude unnecessary headers\n",
    "    \n",
    "    # Parse the rows(player stats) and store them in a list\n",
    "    rows = soup.findAll('tr')[1:]\n",
    "    \n",
    "    # Create the rows for each player and their stats as a list of list\n",
    "    player_stats = []\n",
    "    for i in range(0,len(rows)):\n",
    "        try:\n",
    "            row = [td.getText() for td in rows[i]][1:] # Parses the texts within the tags and excludes the values\n",
    "                                                    # under 'Rk' column since it was also excluded in our headers\n",
    "            player_stats.append(row)\n",
    "        except AttributeError: # For every 20 iteration of this loop, it encounters this error\n",
    "                               # and needs to pass over it and continue on the next iteration\n",
    "            pass\n",
    "\n",
    "    print(\"Scraping and Parsing Complete!\")         \n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    stats = pd.DataFrame(player_stats, columns=headers)\n",
    "    \n",
    "    season_prefix = str(year-1)\n",
    "    season_suffix = str(year)[2:]\n",
    "    \n",
    "    season = \"{}-{}\".format(season_prefix,season_suffix)\n",
    "    \n",
    "    stats['Season'] = season # Add this additional column to indicate the NBA Season\n",
    "    \n",
    "    # Remove unnecessary character under 'Player' column.\n",
    "    stats['Player'] = stats['Player'].str.replace('*','') # Remove '*'\n",
    "    \n",
    "    # Create a csv file from this DataFrame\n",
    "    filename = f'nbaPlayers_stats_{type}_{year}.csv'\n",
    "    filepath = os.path.join(f'{type}_stats',filename)\n",
    "    stats.to_csv(filepath,header=True, index=False)\n",
    "    print(\"Generated csv file last {}: {}\".format(datetime.now(),filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run\n",
    "scrapeNBAStats(2019,type='totals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check csv files by viewing them using pandas DataFrames\n",
    "filename = 'nbaPlayers_stats_totals_2019.csv'\n",
    "filepath = os.path.join(f'{type}_stats',filename)\n",
    "season_df = pd.read_csv(filepath)\n",
    "\n",
    "season_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD 2: `scrapeMVPs()`\n",
    "Scrapes for NBA MVPs from to 1957 to 2019\n",
    "    \n",
    "**OUTPUT:** `nbaMVPs.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeMVPs():\n",
    "    '''\n",
    "    Scrapes for NBA MVPs from to 1957 to 2019\n",
    "    OUTPUT: 'nbaMVPs.csv'\n",
    "    '''\n",
    "    # URL to be requested\n",
    "    url = \"https://www.basketball-reference.com/awards/mvp.html\"\n",
    "\n",
    "    # Create requests object: res\n",
    "    print(\"Now requesting...\", url)\n",
    "    res = requests.get(url)\n",
    "    print(res.raise_for_status)\n",
    "\n",
    "    # Create BeautifulSoup Object: `soup`\n",
    "    soup = BeautifulSoup(res.text, features='lxml')\n",
    "    print(\"Created BeautifulSoup object: soup\")\n",
    "    \n",
    "    # Parse the table\n",
    "    html_table = soup.findAll('tr')[1:] # Sliced first header\n",
    "\n",
    "    # Parse the column headers and store them in a list\n",
    "    headers = [col_head.getText() for col_head in html_table][0].split('\\n')[1:4] # Slicers are intended to exclude unnecessary headers\n",
    "\n",
    "    # Parse the rows and store them in a list\n",
    "    raw_rows = [col_head.getText() for col_head in html_table][1:64] # The scope of slice is from 1957 to 2019\n",
    "    players = []\n",
    "    for row in raw_rows:\n",
    "        season = row[:7]\n",
    "        league = row[7:10]\n",
    "        player = row[10:].split('(V)')[0]\n",
    "        players.append([season,league,player])\n",
    "    \n",
    "    print(\"Scraping and Parsing Complete!\")        \n",
    "    \n",
    "    # Create a pandas DataFrame\n",
    "    mvp = pd.DataFrame(players, columns=headers)\n",
    "    \n",
    "    # Remove additional space on last character of each player. e.g. \"Stephen Curry \" should be \"Stephen Curry\"\n",
    "    corrected_names = []\n",
    "    for i in range(0,len(mvp.index)):\n",
    "        corrected_names.append(mvp.iloc[i]['Player'][:-1])\n",
    "    \n",
    "    # Apply corrections\n",
    "    mvp['Player'] = corrected_names\n",
    "    \n",
    "    # Create a csv file from this DataFrame\n",
    "    filename = 'nbaMVPs.csv'\n",
    "    mvp.to_csv(filename,header=True, index=False)\n",
    "    print(\"Generated csv file last {}: {}\".format(datetime.now(),filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run:\n",
    "scrapeMVPs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparation of Datasets\n",
    "\n",
    "## `datasetFactory.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to import these two modules for this notebook.\n",
    "#from nbaPlayers_StatsScraper import scrapeNBAStats\n",
    "#from nbaPlayers_StatsScraper import scrapeMVPs\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Build a training dataset consisting of complete stats from year 1957 to 2019\n",
    "\n",
    "##### UNCOMMENT TO GENERATE CSVs OF NBA STATS #####\n",
    "years = [i for i in range(1957,2020)]\n",
    "\n",
    "type = 'per_game' # Choose between 'per_game' or 'totals'\n",
    "\n",
    "for i in years:\n",
    "    scrapeNBAStats(year=i,type=type)\n",
    "##### UNCOMMENT BLOCK ENDS HERE ###################\n",
    "\n",
    "# Create an initial DataFrame for the year 1957\n",
    "init_filepath = os.path.join(f'{type}_stats',f'nbaPlayers_stats_{type}_1957.csv')\n",
    "training_df = pd.read_csv(init_filepath)\n",
    "\n",
    "# Then create a for loop to concatenate the stats from 1958 to 2019\n",
    "# to the DataFrame, \"training_df\"\n",
    "years = [year for year in range(1958,2020)]\n",
    "\n",
    "for season in years:\n",
    "    filename = 'nbaPlayers_stats_{}_{}.csv'.format(type,season)\n",
    "    filepath = os.path.join(f'{type}_stats',filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    training_df = pd.concat([training_df,df])\n",
    "\n",
    "# This shall be the training data.\n",
    "# Generate a csv file out of this compilation of stats.\n",
    "training_filename = f'training_data_{type}.csv'\n",
    "training_filepath = os.path.join(f'{type}_stats',training_filename) \n",
    "training_df.to_csv(training_filepath, header=True,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optimizing the Machine Learning Model\n",
    "Before finally using the full training data, we need to know the optimum parameters to be set on the Random Forest Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules from sklearn library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE: Pre-processing\n",
    "# Create DataFrames for building training data\n",
    "\n",
    "type = 'per_game' # Choose between 'per_game' or 'totals'\n",
    "\n",
    "train_df = pd.read_csv(f'training_data_{type}.csv')\n",
    "mvp_df = pd.read_csv('nbaMVPs.csv')\n",
    "\n",
    "# Add an additional feature for the training data: 'MVP'\n",
    "# contains only two unique values of 0 and 1. 0 for 'not MVP' and 1 for 'MVP'\n",
    "\n",
    "# Add additional column ['Season-Player'] on train_df and mvp_df\n",
    "# This additional column shall served as an MVP marker reference\n",
    "train_df['Season-Player'] = train_df['Season'] + '_' + train_df['Player'].str.replace(' ','_')\n",
    "mvp_df['Season-Player'] = mvp_df['Season'] + '_' + mvp_df['Player'].str.replace(' ','_')\n",
    "\n",
    "# Create a list that shall contain the values for the 'MVP' column for train_df\n",
    "\n",
    "mvp_colvals = [] # The contents of this list shall be stored under the new column,\"MVP\" on train_df\n",
    "\n",
    "# Convert the 'Season-Player' column into an array for faster computing\n",
    "train_array = np.array(train_df['Season-Player'])\n",
    "mvp_array = np.array(mvp_df['Season-Player'])\n",
    "\n",
    "# Perform a for loop to store values on mvp_colvals\n",
    "for val in train_array:\n",
    "    if val in mvp_array:\n",
    "        mvp_colvals.append(1)\n",
    "    else:\n",
    "        mvp_colvals.append(0)\n",
    "\n",
    "# Add additional column 'MVP' on train_df. This column shall be the target(y) for our training dataset\n",
    "train_df['MVP'] = mvp_colvals\n",
    "\n",
    "# Update the 'training_data.csv' by overwriting it with the data under train_df\n",
    "train_df.to_csv('training_data.csv', header=True,index=False)\n",
    "\n",
    "# Drop NaN values from train_df\n",
    "train_df.dropna(axis=0,inplace=True)\n",
    "\n",
    "# Set index to 'Season-Player' column\n",
    "train_df = train_df.set_index('Season-Player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE: Set features & target, apply train_test_split, define model\n",
    "\n",
    "features = ['G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P','3PA', '3P%', '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB','DRB', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS']\n",
    "X = train_df[features]\n",
    "y = train_df['MVP']\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y,train_size=0.75,test_size=0.25,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-evaluation: Use Mean Absolute Error and validate across different number of estimators\n",
    "def getMAEs(n_est, X_train, X_valid, y_train, y_valid):\n",
    "    for estimators in n_est:\n",
    "        model = RandomForestRegressor(n_estimators=estimators,random_state=0)\n",
    "        model.fit(X_train,y_train)\n",
    "        model_predictions = model.predict(X_valid)\n",
    "        mae = mean_absolute_error(y_valid,model_predictions)\n",
    "        print(\"MAE at {} estimators:\".format(estimators),mae)\n",
    "        \n",
    "n = [1000,1500,2000]\n",
    "getMAEs(n, X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model. Choose the optimum number of n_estimators.\n",
    "model = RandomForestRegressor(n_estimators=1000,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT: Train the model\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "model_predictions = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE:\n",
    "validation = X_valid.copy()\n",
    "validation['Actual MVP'] = y_valid\n",
    "validation['Prediction'] = model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation[validation['Actual MVP'] == 1]\n",
    "#validation[validation['Prediction'] >= 0.2]\n",
    "validation.nlargest(5,'Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST PREDICTION\n",
    "# Create DataFrames for building test data:\n",
    "test_df = pd.read_csv('nbaPlayers_statsPerGame_2019.csv')\n",
    "\n",
    "# Drop NaN values from test_df\n",
    "test_df.dropna(axis=0,how='any',inplace=True)\n",
    "\n",
    "# Add 'Season-Player' column\n",
    "test_df['Season-Player'] = test_df['Season'] + '_' + test_df['Player'].str.replace(' ','_')\n",
    "\n",
    "# Set index to 'Season-Player' column\n",
    "test_df = test_df.set_index('Season-Player')\n",
    "\n",
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL, FIT MODEL, PREDICT\n",
    "model_final = RandomForestRegressor(n_estimators=1000,random_state=0)\n",
    "model_final.fit(X,y)\n",
    "model_final_preds = model_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION OF TEST DATA\n",
    "results = X_test.copy()\n",
    "results['Prediction'] = model_final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "results.nlargest(5,'Prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
